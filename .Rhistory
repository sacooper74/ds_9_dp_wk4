# set as factor
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
# fit random forest
modFit <- train(y ~., data=subset(vowel.train, select = -c(y)), method="rf", prox=T) # outcome set to Species, prox gives more info
## Week 4 Quiz
# Question 1
library(ElemStatLearn); data(vowel.train); data(vowel.test); library(caret)
# set as factor
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
# fit random forest
modFit <- train(y ~., data=subset(vowel.train, select = -c(y)), method="rf", prox=T) # outcome set to Species, prox gives more info
# fit random forest
modFit <- train(y ~., data=subset(vowel.train, select = -c("y")), method="rf", prox=T) # outcome set to Species, prox gives more info
# fit random forest
modFit <- train(y ~., data=subset(vowel.train, select = -c('y')), method="rf", prox=T) # outcome set to Species, prox gives more info
# fit random forest
modFit <- train(y ~., data=vowel.train, method="rf", prox=T) # outcome set to Species, prox gives more info
pred_gbm <- predict(mod_gbm, vowel.test)
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm", verbose = F)
pred_rf <- predict(mod_rf, vowel.test)
pred_rf <- predict(modFit, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
# accuracy
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
# fit models
set.seed(33833)
modFit <- train(y ~., data=vowel.train, method="rf", prox=T) # outcome set to Species, prox gives more info
mod_rf <- train(y ~., data=vowel.train, method="rf", prox=T) # outcome set to Species, prox gives more info
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm", verbose = F)
shiny::runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/Horsepower')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/Horsepower')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/Horsepower')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/TabApp')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/Brushed')
install.packages("miniUI")
version
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/week1/Gadget')
myFirstGadget <- function() {
ui <- miniPage(
gadgetTitleBar("My First Gadget")
)
server <- function(input, output, session) {
# The Done button closes the app
observeEvent(input$done, {
stopApp()
})
}
runGadget(ui, server)
}
myFirstGadget()
library(shiny)
library(miniUI)
multiplyNumbers <- function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
selectInput("num1", "First Number", choices=numbers1),
selectInput("num2", "Second Number", choices=numbers2)
)
)
server <- function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 * num2)
})
}
runGadget(ui, server)
}
multiplyNumbers()
# Gadget with arguments
library(shiny)
library(miniUI)
multiplyNumbers <- function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
selectInput("num1", "First Number", choices=numbers1),
selectInput("num2", "Second Number", choices=numbers2)
)
)
server <- function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 * num2)
})
}
runGadget(ui, server)
}
multiplyNumbers()
multiplyNumbers(2, 3)
library(caret); library(rpart.plot); library(randomForest)
trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# All blanks, "NA" and division errors are interpreted as NA values
training <- read.csv(trainUrl, na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(testUrl, na.strings=c("NA","#DIV/0!",""))
# delete columns with missing values
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
# remove first 7 columns
training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]
# dim(training); dim(testing)
# partition the data
inTrain <- createDataPartition(training$classe, p=0.7, list = F)
train <- training[inTrain,]
validate <- training[-inTrain,]
View(testing)
View(validate)
set.seed(121)
control_rpart <- rpart.control(xval = 5)
# fit the model, cross-validated 5 times
fit_rpart <- rpart(classe ~ ., data = training, method = "class", control = control_rpart)
# note: we could have used caret
# model fitted on a mac where rattle won't load, will use rpart.plot()
prp(fit_rpart)
# note: we could have used caret
# model fitted on a mac where rattle won't load, will use rpart.plot()
prp(fit_rpart)
# prediction
predict_rpart <- predict(fit_rpart, validate, type = "class")
cm_rpart <- confusionMatrix(predict_rpart, validate$classe)
cm_rpart
fit_rf <- randomForest(classe ~ ., data = training)
# Here is the code for model training with RF and cross validation, however it wouldn't complete on my machine
# fit_rf <- train(classe ~ ., data = training, method = "rf", trControl = control_rf)
print(fit_rf)
# prediction via caret
predict_rf <- predict(fit_rf, validate, type = "class")
cm_rf <- confusionMatrix(predict_rf, validate$classe)
cm_rf
fit_rf <- randomForest(classe ~ ., data = train)
# fit the model, cross-validated 5 times
fit_rpart <- rpart(classe ~ ., data = train, method = "class", control = control_rpart)
# note: we could have used caret
# model fitted on a mac where rattle won't load, will use rpart.plot()
prp(fit_rpart)
# prediction
predict_rpart <- predict(fit_rpart, validate, type = "class")
cm_rpart <- confusionMatrix(predict_rpart, validate$classe)
cm_rpart
# Here is the code for model training with RF and cross validation, however it wouldn't complete on my machine
# fit_rf <- train(classe ~ ., data = training, method = "rf", trControl = control_rf)
print(fit_rf)
# prediction via caret
predict_rf <- predict(fit_rf, validate, type = "class")
cm_rf <- confusionMatrix(predict_rf, validate$classe)
cm_rf
control_rf <- trainControl(method="cv", number = 5, verboseIter = T)
# Here is the code for model training with RF and cross validation, however it wouldn't complete on my machine
fit_rf <- train(classe ~ ., data = training, method = "rf", trControl = control_rf)
# Here is the code for model training with RF and cross validation, however it wouldn't complete on my machine
fit_rf <- train(classe ~ ., data = train, , method = "rf", trControl = control_rf)
# Here is the code for model training with RF and cross validation, however it wouldn't complete on my machine
fit_rf <- train(classe ~ ., data = train, method = "rf", trControl = control_rf)
library(caret); library(rpart.plot); library(randomForest)
trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# All blanks, "NA" and division errors are interpreted as NA values
training <- read.csv(trainUrl, na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(testUrl, na.strings=c("NA","#DIV/0!",""))
# delete columns with missing values
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
# remove first 7 columns
training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]
# dim(training); dim(testing)
# partition the data
inTrain <- createDataPartition(training$classe, p=0.7, list = F)
train <- training[inTrain,]
validate <- training[-inTrain,]
set.seed(121)
control_rf <- trainControl(method="cv", number = 5, verboseIter = T)
# train with cv enabled
fit_rf <- train(classe ~ ., data = train, method = "rf", trControl = control_rf)
print(fit_rf)
# prediction via caret
predict_rf <- predict(fit_rf, validate, type = "class")
# prediction via caret
predict_rf <- predict(fit_rf, validate)
cm_rf <- confusionMatrix(predict_rf, validate$classe)
cm_rf
## Leaflet
install.packages("library")
knitr::opts_chunk$set(echo = FALSE)
library(leaflet)
install.packages("leaflet")
library(leaflet)
my_map
my_map <- leaflet() %>%
addTiles()
my_map
my_map <- leaflet() %>%
addTiles()
my_map
library(leaflet)
my_map <- leaflet() %>%
addTiles()
my_map
library(leaflet)
my_map <- leaflet() %>%
addTiles()
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2, lng = 76.5, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2, lng = 76.5, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng = 76.2980803, popup = "mystery location") # adds mapping data from Open Street Map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng = 76.2980803, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng = 76.5898801, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng = -76.5898801, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- my_map() %>%
addTiles()
my_map
my_map <- my_map %>%
addTiles()
my_map
my_map <- my_map %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng=-76.5898801, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- my_map %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng=-76.5898801, popup = "mystery location") # adds mapping data from Open Street Map
my_map
my_map <- my_map %>% # use pipe operators for layers
addMarkers(lat=39.2980803, lng=-76.5898801, popup = "mystery location") # adds mapping data from Open Street Map
my_map
## many markers
set.seed(2016-04-25)
df <- data.frame(lat = runif(20, min = 39.2, max = 39.3),
lng = runif(20, min = -76.6, max = -76.5))
df <- data.frame(lat = runif(20, min = 39.2, max = 39.3),
lng = runif(20, min = -76.6, max = -76.5))
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
## Custom markers
hopkinsIcon <- makeIcon(
iconUrl = "http://brand.jhu.edu/content/uploads/2014/06/university.shield.small_.blue_.png",
iconWidth = 31*215/230, iconHeight = 31,
iconAnchorX = 31*215/230/2, iconAnchorY = 16
)
hopkinsLatLong <- data.frame(
lat = c(39.2973166, 39.3288851, 39.2906617),
lng = c(-76.5929798, -76.6206598, -76.5469683))
hopkinsLatLong %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = hopkinsIcon)
## Multiple popups
hopkinsSites <- c(
"<a href='http://www.jhsph.edu/'>East Baltimore Campus</a>",
"<a href='https://apply.jhu.edu/visit/homewood/'>Homewood Campus</a>",
"<a href='http://www.hopkinsmedicine.org/johns_hopkins_bayview/'>Bayview Medical Center</a>",
"<a href='http://www.peabody.jhu.edu/'>Peabody Institute</a>",
"<a href='http://carey.jhu.edu/'>Carey Business School</a>"
)
hopkinsLatLong %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = hopkinsIcon, popup = hopkinsSites)
## Mapping clusters
df <- data.frame(lat = runif(500, min = 39.25, max = 39.35),
lng = runif(500, min = -76.65, max = -76.55))
df %>%
leaflet() %>%
addTiles() %>%
addMarkers(clusterOptions = markerClusterOptions())
## Mapping circles
df <- data.frame(lat = runif(20, min = 39.25, max = 39.35),
lng = runif(20, min = -76.65, max = -76.55))
df %>%
leaflet() %>%
addTiles() %>%
addCircleMarkers()
## Drawing Circles
md_cities <- data.frame(name = c("Baltimore", "Frederick", "Rockville", "Gaithersburg",
"Bowie", "Hagerstown", "Annapolis", "College Park", "Salisbury", "Laurel"),
pop = c(619493, 66169, 62334, 61045, 55232,
39890, 38880, 30587, 30484, 25346),
lat = c(39.2920592, 39.4143921, 39.0840, 39.1434, 39.0068, 39.6418, 38.9784, 38.9897, 38.3607, 39.0993),
lng = c(-76.6077852, -77.4204875, -77.1528, -77.2014, -76.7791, -77.7200, -76.4922, -76.9378, -75.5994, -76.8483))
md_cities %>%
leaflet() %>%
addTiles() %>%
addCircles(weight = 1, radius = sqrt(md_cities$pop) * 30)
md_cities %>%
leaflet() %>%
addTiles() %>%
addCircles(weight = 10, radius = sqrt(md_cities$pop) * 30) # adding circles with radius scaled relative to population
md_cities %>%
leaflet() %>%
addTiles() %>%
addCircles(weight = 1, radius = sqrt(md_cities$pop) * 30) # adding circles with radius scaled relative to population
## Drawing Rectangles
leaflet() %>%
addTiles() %>%
addRectangles(lat1 = 37.3858, lng1 = -122.0595,
lat2 = 37.3890, lng2 = -122.0625)
## Adding Legends
df <- data.frame(lat = runif(20, min = 39.25, max = 39.35),
lng = runif(20, min = -76.65, max = -76.55),
col = sample(c("red", "blue", "green"), 20, replace = TRUE),
stringsAsFactors = FALSE)
df %>%
leaflet() %>%
addTiles() %>%
addCircleMarkers(color = df$col) %>%
addLegend(labels = LETTERS[1:3], colors = c("blue", "red", "green"))
df %>%
leaflet() %>%
addTiles() %>%
addCircleMarkers(color = df$col) %>% # coloured by dataframe colours
addLegend(labels = LETTERS[1:3], colors = c("blue", "red", "green"))
my_map <- my_map %>% # use pipe operators for layers
addMarkers(lat=53.130991, lng=-6.240597, popup = "djouce") # adds mapping data from Open Street Map
my_map
rm(list=ls())
my_map <- my_map %>% # use pipe operators for layers
addMarkers(lat=53.130991, lng=-6.240597, popup = "djouce") # adds mapping data from Open Street Map
my_map
my_map <- leaflet() %>% # use pipe operators for layers
addMarkers(lat=53.130991, lng=-6.240597, popup = "djouce") # adds mapping data from Open Street Map
my_map
map <- data.frame(lat=53.130991, lng=-6.240597)
map %>%
leaflet() %>% # use pipe operators for layers
addMarkers(popup = "djouce") # adds mapping data from Open Street Map
map %>%
leaflet() %>% # use pipe operators for layers
addTiles() %>%
addMarkers(popup = "djouce") # adds mapping data from Open Street Map
icon_imra <- makeIcon(iconUrl = "https://www.imra.ie/images/imra.gif")
map %>%
leaflet() %>% # use pipe operators for layers
addTiles() %>%
addMarkers(icon = icon_imra, popup = "djouce") # adds mapping data from Open Street Map
icon_imra <- makeIcon(iconUrl = "https://www.imra.ie/images/imra.gif",
iconWidth = 31*215/230, iconHeight = 31,
iconAnchorX = 31*215/230/2, iconAnchorY = 16)
map %>%
leaflet() %>% # use pipe operators for layers
addTiles() %>%
addMarkers(icon = icon_imra, popup = "djouce") # adds mapping data from Open Street Map
icon_imra <- makeIcon(iconUrl = "https://image.freepik.com/free-icon/running-man_318-1564.jpg",
iconWidth = 31*215/230, iconHeight = 31,
iconAnchorX = 31*215/230/2, iconAnchorY = 16)
map %>%
leaflet() %>% # use pipe operators for layers
addTiles() %>%
addMarkers(icon = icon_imra, popup = "djouce") # adds mapping data from Open Street Map
?ftype
library(pryr)
install.packages("pryr")
library(pryr)
?ftype
ftype(predict)
ftype(colSums)
ftype(dgamma)
ftype(show)
ftype(lm)
ftype(mean)
install.packages("plotly")
library(plotly)
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
data(mtcars)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
head(mtcars)
plot_ly(mtcars, x = "wt", y = "mpg", mode = "markers")
library(plotly)
data(mtcars)
head(mtcars)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
plot_ly(mtcars, x = ~wt, y = ~mpg, mode = "markers")
summary(cars)
plot_ly(mtcars, x = ~wt, y = ~mpg, mode = "markers") # https://github.com/ropensci/plotly/issues/722
plot_ly(mtcars, x = ~wt, y = ~mpg, mode = "markers", color = ~disp)
shiny::runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk1/6. Brushed')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk1/4. Horsepower')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk1/3. RandomApp')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk1/5. TabApp')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
shiny::runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
head(iris)
shiny::runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject')
runlog <- read.csv("runlog.csv")
# libraries
setwd("C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk4/CourseProject")
runlog <- read.csv("runlog.csv")
head(runlog)
str(runlog)
runlog <- read.csv("runlog.csv", stringsAsFactors = FALSE)
str(runlog)
runlog$AvgPace <- as.POSIXct(runlog$AvgPace, format = "%M:%S")
str(runlog)
library(tidyverse)
runlog$AvgPace <- col_time(runlog$AvgPace, format = "%M:%S")
runlog <- read.csv("runlog.csv", stringsAsFactors = FALSE)
str(runlog)
runlog$AvgPace <- strptime(runlog$AvgPace, "%M:%S")
str(runlog)
# create the model
# linear model to predict average pace based upon average cadence
model1 <- lm(AvgPace ~ AvgCadence, data = runlog)
# import the dataset
runlog <- read_csv("runlog.csv",
col_types = list(AvgPace = col_time(format = "%M:%S")))
str(runlog)
head(runlog)
# create the model
# linear model to predict average pace based upon average cadence
model1 <- lm(AvgPace ~ AvgCadence, data = runlog)
cad_input <- 180
predict(model1, newdata = data.frame(AvgCadence = cad_input))
cad_input <- as.character(180)
predict(model1, newdata = data.frame(AvgCadence = cad_input))
plot(runlog$AvgPace, runlog$AvgCadence, xlab = "Average Pace", ylab = "Average Cadence")
head(runlog)
abline(model1, col = "red", lwd = 2)
plot(runlog$AvgPace, runlog$AvgCadence, xlab = "Average Pace", ylab = "Average Cadence")
abline(model1, col = "red", lwd = 2)
points(cad_input, model1pred(), col = "red", pch = 16, cex = 2)
runApp()
runlog$AvgCadence <- as.numeric(runlog$AvgCadence)
head(runlog)
# import the dataset
runlog <- read_csv("runlog.csv",
col_types = list(AvgPace = col_time(format = "%M:%S")))
runlog$AvgCadence <- as.numeric(runlog$AvgCadence)
head(runlog)
# create the model
# linear model to predict average pace based upon average cadence
model1 <- lm(AvgPace ~ AvgCadence, data = runlog)
runApp()
runApp()
runApp()
runApp()
plot(runlog$AvgPace, runlog$AvgCadence, xlab = "Average Pace", ylab = "Average Cadence")
abline(model1, col = "red", lwd = 2)
abline(mean(runlog$AvgCadence))
abline(mean(runlog$AvgPace))
abline()
runApp()
runApp('C:/Users/steve.a.cooper/Google Drive/Coursera - DS/ds_9_dp/ds_9_dp_wk1/6. Brushed')
runApp()
plot(runlog$AvgPace, runlog$AvgCadence, xlab = "Average Pace", ylab = "Average Cadence")
abline(model1, col = "red", lwd = 2)
points(cad_input, model1pred(), col = "red", pch = 5, cex = 2, lwd = 10)
plot(iris$Sepal.Length, iris$Sepal.Width)
abline(lm(iris$Sepal.Length ~ iris$Sepal.Width))
iris_mod <- lm(Sepal.Length ~ ., data = iris)
abline(iris_mod)
iris_mod$coefficients
model1$coefficients
# linear model to predict average pace based upon average cadence
model1 <- lm(AvgPace ~ AvgCadence, data = runlog)
plot(runlog$AvgPace, runlog$AvgCadence, xlab = "Average Pace", ylab = "Average Cadence")
rm(iris_mod)
rm(cad_input)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
model1$coefficients
runApp()
model1$coefficients[2]
model1$coefficients[1]
runApp()
install.packages("rsconnect")
library(rsconnect)
rsconnect::setAccountInfo(name='sacooper74',
token='05EE20720B21959A51FCECC17F2F463F',
secret='<SECRET>')
rsconnect::setAccountInfo(name='sacooper74', token='05EE20720B21959A51FCECC17F2F463F', secret='z6W5spa8HhL5fa7kEDjZl4+ECRxwpgyqyyFCrKQS')
